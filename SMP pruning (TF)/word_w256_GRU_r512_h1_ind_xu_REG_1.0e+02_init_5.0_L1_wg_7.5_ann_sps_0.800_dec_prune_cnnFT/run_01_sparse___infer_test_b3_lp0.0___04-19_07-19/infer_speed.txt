Using GPU #: 0
Inference batch size: 25
Inference beam size: 3

101.10486153403151