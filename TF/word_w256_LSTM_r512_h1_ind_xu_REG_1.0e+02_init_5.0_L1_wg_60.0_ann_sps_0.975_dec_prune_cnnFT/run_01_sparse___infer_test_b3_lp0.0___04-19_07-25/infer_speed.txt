Using GPU #: 0
Inference batch size: 25
Inference beam size: 3

378.15406679638977