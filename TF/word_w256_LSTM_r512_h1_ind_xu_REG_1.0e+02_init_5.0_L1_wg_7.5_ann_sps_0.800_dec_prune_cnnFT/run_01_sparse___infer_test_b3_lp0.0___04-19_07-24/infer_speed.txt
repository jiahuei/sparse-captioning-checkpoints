Using GPU #: 0
Inference batch size: 25
Inference beam size: 3

357.5991472807809